{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compression & Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Python libraries\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huffman Code class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class HuffmanCode from scratch\n",
    "class HuffmanCode:\n",
    "    \n",
    "    # Return a Huffman code for an ensemble with distribution p\n",
    "    def get_code(self, p_symbols):\n",
    "        \n",
    "        # Init validation\n",
    "        n = len(p_symbols)\n",
    "        if n == 0:\n",
    "            return dict()\n",
    "        elif n == 1:\n",
    "            return dict(zip(p_symbols.keys(), ['1']))\n",
    "        \n",
    "        # Ensure probabilities sum to 1\n",
    "        self._normalize_weights(p_symbols)\n",
    "        \n",
    "        # Returns Huffman code\n",
    "        return self._get_code(p_symbols);\n",
    "    \n",
    "    # (Private) Calculate Huffman code\n",
    "    def _get_code(self, p):\n",
    "        \n",
    "        # Base case of only two symbols, assign 0 or 1 arbitrarily\n",
    "        if len(p) == 2:\n",
    "            return dict(zip(p.keys(), ['0', '1']))\n",
    "        \n",
    "        # Create a new distribution by merging lowest prob pair\n",
    "        p_prime = p.copy()\n",
    "        s1, s2 = self._get_lowest_prob_pair(p)\n",
    "        p1, p2 = p_prime.pop(s1), p_prime.pop(s2)\n",
    "        p_prime[s1 + s2] = p1 + p2\n",
    "        \n",
    "        # Recurse and construct code on new distribution\n",
    "        code = self._get_code(p_prime)\n",
    "        symbol = s1 + s2\n",
    "        s1s2 = code.pop(symbol)\n",
    "        code[s1], code[s2] = s1s2 + '0', s1s2 + '1'\n",
    "        \n",
    "        return code;\n",
    "    \n",
    "    # Return pair of symbols from distribution p with lowest probabilities\n",
    "    def _get_lowest_prob_pair(self, p):\n",
    "        \n",
    "        # Ensure there are at least 2 symbols in the dist.\n",
    "        if len(p) >= 2:\n",
    "            sorted_p = sorted(p.items(), key=lambda x: x[1])\n",
    "            return sorted_p[0][0], sorted_p[1][0];\n",
    "        \n",
    "        return (None, None);\n",
    "    \n",
    "    # Makes sure all weights add up to 1\n",
    "    def _normalize_weights(self, p_symbols, t_weight=1.0):\n",
    "        n = sum(p_symbols.values())\n",
    "        \n",
    "        if n != t_weight:\n",
    "            for s in p_symbols:\n",
    "                p_symbols[s] = p_symbols[s] / n;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Huffman Code instance\n",
    "hc = HuffmanCode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Compression with current Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file in low level (Bytes)\n",
    "def get_file_bytes(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        return bytearray(f.read());\n",
    "    return None;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return shannon entropy\n",
    "def entropy_shannon(labels, base=None):\n",
    "    value, counts = np.unique(labels, return_counts=True)\n",
    "    return entropy(counts, base=base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading target image\n",
    "file_path = \"../data/text/book-1.txt\"\n",
    "text_byte_list = get_file_bytes(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theoretical compression percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the compression percentage (%)\n",
    "def calc_compression_percentage(curr_size, new_size):\n",
    "    return round((curr_size - new_size) / curr_size * 100, 2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.59266006221856"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate entropy of image\n",
    "curr_entropy = entropy_shannon(text_byte_list, 2)\n",
    "curr_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.59 %\n"
     ]
    }
   ],
   "source": [
    "# Real compression percentage (%)\n",
    "curr_size = 8\n",
    "new_size = curr_entropy\n",
    "compress_rate = calc_compression_percentage(curr_size, new_size)\n",
    "print(compress_rate, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real compression percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate code frequency\n",
    "def get_term_freq(term_list):\n",
    "    term_freq = {}\n",
    "    terms_count = dict(Counter(term_list))\n",
    "    \n",
    "    for key, value in terms_count.items():\n",
    "        if isinstance(key, int):\n",
    "            key = chr(key)\n",
    "        term_freq[key] = value\n",
    "    \n",
    "    return term_freq;\n",
    "\n",
    "# Build the compress file\n",
    "def create_compress_file(byte_list, code_list):\n",
    "    compress_list = []\n",
    "    \n",
    "    for symbol in byte_list:\n",
    "        key = chr(symbol)\n",
    "        new_symbol = code_list[key]\n",
    "        compress_list.append(new_symbol)\n",
    "    \n",
    "    # Return compress file\n",
    "    return \"\".join(compress_list)\n",
    "\n",
    "# Compressing file\n",
    "def get_compress_file(byte_list):\n",
    "    \n",
    "    # Get symbols frequency\n",
    "    term_freq = get_term_freq(byte_list)\n",
    "    \n",
    "    # Normalize term frequency\n",
    "    n = sum(term_freq.values())\n",
    "    for term in term_freq:\n",
    "        term_freq[term] = term_freq[term] / n;\n",
    "    \n",
    "    # Get Huffman coding\n",
    "    h_code = hc.get_code(term_freq)\n",
    "    \n",
    "    # Compressing file with Huffman code\n",
    "    compress_file = create_compress_file(byte_list, h_code)\n",
    "            \n",
    "    return compress_file, h_code;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compressing initial text file\n",
    "compress_file, h_code = get_compress_file(text_byte_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.19 %\n"
     ]
    }
   ],
   "source": [
    "# Real compression percentage (%)\n",
    "curr_size = len(text_byte_list)\n",
    "new_size = len(compress_file) / 8\n",
    "compress_rate = calc_compression_percentage(curr_size, new_size)\n",
    "print(compress_rate, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compression changing Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_low_entropy(byte_list):\n",
    "    best_byte_list = []\n",
    "    best_entropy = 8\n",
    "    best_key = -1\n",
    "    \n",
    "    for curr_key in range(256):\n",
    "        curr_byte_list = [(byte ^ curr_key) for byte in byte_list]\n",
    "        curr_entropy = entropy_shannon(curr_byte_list, 2)\n",
    "        \n",
    "        if curr_entropy < best_entropy:\n",
    "            print('curr_entropy:',curr_entropy, ', best_entropy:', best_entropy, ', curr_key:', curr_key)\n",
    "            best_entropy = curr_entropy\n",
    "            best_key = curr_key\n",
    "            best_byte_list = curr_byte_list.copy()\n",
    "    \n",
    "    return best_byte_list, best_entropy, best_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr_entropy: 4.59266006221856 , best_entropy: 8 , curr_key: 0\n",
      "curr_entropy: 4.592660062218559 , best_entropy: 4.59266006221856 , curr_key: 33\n"
     ]
    }
   ],
   "source": [
    "best_byte_list, best_entropy, best_key = find_low_entropy(text_byte_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.592660062218559"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new file\n",
    "file_path = file_path.replace('.txt', '-new.txt')\n",
    "with open(file_path, 'w+b') as f:\n",
    "    binary_format = bytearray(best_byte_list)\n",
    "    f.write(binary_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p><a href=\"https://ansegura7.github.io/DataCompression/\">Â« Home</a></p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

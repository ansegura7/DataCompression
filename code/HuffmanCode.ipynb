{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huffman Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Created by Andrés Segura Tinoco**  \n",
    "- **Created on June 20, 2019**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In computer science and information theory, a **Huffman Code** is a particular type of optimal prefix code that is commonly used for lossless data compression. The output from Huffman's algorithm can be viewed as a variable-length code table for encoding a source symbol (such as a character in a file). The algorithm derives this table from the estimated probability or frequency of occurrence (weight) for each possible value of the source symbol. <a href='#link_one'>[1]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Python libraries\n",
    "import numpy as np\n",
    "import timeit\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Huffman Code from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class HuffmanCode from scratch\n",
    "class HuffmanCode:\n",
    "    \n",
    "    # Return a Huffman code for an ensemble with distribution p\n",
    "    def get_code(self, p_symbols):\n",
    "        \n",
    "        # Init validation\n",
    "        n = len(p_symbols)\n",
    "        if n == 0:\n",
    "            return dict()\n",
    "        elif n == 1:\n",
    "            return dict(zip(p_symbols.keys(), ['1']))\n",
    "        \n",
    "        # Ensure probabilities sum to 1\n",
    "        self._normalize_weights(p_symbols)\n",
    "        \n",
    "        # Returns Huffman code\n",
    "        return self._get_code(p_symbols);\n",
    "    \n",
    "    # (Private) Calculate Huffman code\n",
    "    def _get_code(self, p):\n",
    "        \n",
    "        # Base case of only two symbols, assign 0 or 1 arbitrarily\n",
    "        if len(p) == 2:\n",
    "            return dict(zip(p.keys(), ['0', '1']))\n",
    "        \n",
    "        # Create a new distribution by merging lowest prob pair\n",
    "        p_prime = p.copy()\n",
    "        s1, s2 = self._get_lowest_prob_pair(p)\n",
    "        p1, p2 = p_prime.pop(s1), p_prime.pop(s2)\n",
    "        p_prime[s1 + s2] = p1 + p2\n",
    "        \n",
    "        # Recurse and construct code on new distribution\n",
    "        code = self._get_code(p_prime)\n",
    "        symbol = s1 + s2\n",
    "        s1s2 = code.pop(symbol)\n",
    "        code[s1], code[s2] = s1s2 + '0', s1s2 + '1'\n",
    "        \n",
    "        return code;\n",
    "    \n",
    "    # (Private) Return pair of symbols from distribution p with lowest probabilities\n",
    "    def _get_lowest_prob_pair(self, p):\n",
    "        \n",
    "        # Ensure there are at least 2 symbols in the dist.\n",
    "        if len(p) >= 2:\n",
    "            sorted_p = sorted(p.items(), key=lambda x: x[1])\n",
    "            return sorted_p[0][0], sorted_p[1][0];\n",
    "        \n",
    "        return (None, None);\n",
    "    \n",
    "    # (Private) Makes sure all weights add up to 1\n",
    "    def _normalize_weights(self, p_symbols, t_weight=1.0):\n",
    "        n = sum(p_symbols.values())\n",
    "        \n",
    "        if n != t_weight:\n",
    "            for s in p_symbols:\n",
    "                p_symbols[s] = p_symbols[s] / n;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input:**\n",
    "$$ A = \\{ a_1, a_2, a_3, ..., a_n \\} \\tag{1} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ W = \\{ w_1, w_2, w_3, ..., w_n \\} \\tag{2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ n = |A| $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output:**\n",
    "$$ C(A, W) = \\{ c_1, c_2, c_3, ..., c_n \\} \\tag{3} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Target:**\n",
    "$$ L(C) = \\sum_{i=1}^n{w_i . length(c_i)} \\tag{4} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ L(C) < L(T)\\;for\\;any\\;code\\;T(A, W) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Huffman Code instance\n",
    "hc = HuffmanCode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': '1'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alphabet with 1 symbol\n",
    "sample_1 = { 'a': 1.0 }\n",
    "hc.get_code(sample_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': '0', 'c': '10', 'b': '11'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alphabet with 3 symbols and total probability less than 1\n",
    "sample_2 = { 'a': 0.6, 'b': 0.25, 'c': 0.1 }\n",
    "hc.get_code(sample_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'e': '10', 'c': '11', 'd': '00', 'a': '010', 'b': '011'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alphabet with 5 symbols and total probability equal than 1.0\n",
    "sample_3 = { 'a': 0.10, 'b': 0.15, 'c': 0.30, 'd': 0.16, 'e': 0.29 }\n",
    "hc.get_code(sample_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compress Image with Huffman Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example is with a PNG image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file in low level (Bytes)\n",
    "def get_file_bytes(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        return bytearray(f.read());\n",
    "    return None;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading target image\n",
    "file_path = \"../data/img/example-3.png\"\n",
    "image_byte_list = get_file_bytes(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate code frequency\n",
    "def get_term_freq(term_list):\n",
    "    term_freq = {}\n",
    "    terms_count = dict(Counter(term_list))\n",
    "    \n",
    "    for key, value in terms_count.items():\n",
    "        if isinstance(key, int):\n",
    "            key = str(key)\n",
    "        term_freq[key] = value\n",
    "    \n",
    "    return term_freq;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alphabet with 256 symbols\n",
    "term_freq = get_term_freq(image_byte_list)\n",
    "len(term_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999994"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize term frequency\n",
    "n = sum(term_freq.values())\n",
    "for term in term_freq:\n",
    "    term_freq[term] = term_freq[term] / n;\n",
    "sum(term_freq.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Huffman coding\n",
    "hf_code = hc.get_code(term_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a huffman dataframe with the codes and frequency of each of them\n",
    "def create_huffman_df(code_list, term_freq):\n",
    "    codes = pd.DataFrame([code_list, term_freq]).T\n",
    "    codes.reset_index(level=0, inplace=True)\n",
    "    codes.columns = [\"byte\", \"code\", \"frequency\"]\n",
    "    codes['symbol'] = [chr(int(b)) for b in codes[\"byte\"]]\n",
    "    codes = codes[[\"byte\", \"symbol\", \"code\", \"frequency\"]]\n",
    "    \n",
    "    return codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>byte</th>\n",
       "      <th>symbol</th>\n",
       "      <th>code</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>01110</td>\n",
       "      <td>0.0284127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\u0001</td>\n",
       "      <td>110011</td>\n",
       "      <td>0.0197444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>\\n</td>\n",
       "      <td>0110101</td>\n",
       "      <td>0.00697332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>d</td>\n",
       "      <td>01000010</td>\n",
       "      <td>0.00314809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101</td>\n",
       "      <td>e</td>\n",
       "      <td>110101111</td>\n",
       "      <td>0.0025088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>102</td>\n",
       "      <td>f</td>\n",
       "      <td>00101111</td>\n",
       "      <td>0.00298616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>103</td>\n",
       "      <td>g</td>\n",
       "      <td>00011000</td>\n",
       "      <td>0.0028726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>104</td>\n",
       "      <td>h</td>\n",
       "      <td>10000101</td>\n",
       "      <td>0.00378738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>105</td>\n",
       "      <td>i</td>\n",
       "      <td>110010111</td>\n",
       "      <td>0.00247305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>106</td>\n",
       "      <td>j</td>\n",
       "      <td>101101001</td>\n",
       "      <td>0.00226065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>107</td>\n",
       "      <td>k</td>\n",
       "      <td>111000010</td>\n",
       "      <td>0.00255716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>108</td>\n",
       "      <td>l</td>\n",
       "      <td>00110110</td>\n",
       "      <td>0.00307028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>109</td>\n",
       "      <td>m</td>\n",
       "      <td>111010011</td>\n",
       "      <td>0.00260974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11</td>\n",
       "      <td></td>\n",
       "      <td>11000010</td>\n",
       "      <td>0.00477786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>110</td>\n",
       "      <td>n</td>\n",
       "      <td>00101001</td>\n",
       "      <td>0.00295672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>111</td>\n",
       "      <td>o</td>\n",
       "      <td>00111110</td>\n",
       "      <td>0.00311865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>112</td>\n",
       "      <td>p</td>\n",
       "      <td>0110011</td>\n",
       "      <td>0.00692705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>113</td>\n",
       "      <td>q</td>\n",
       "      <td>00101010</td>\n",
       "      <td>0.00296303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>114</td>\n",
       "      <td>r</td>\n",
       "      <td>110000000</td>\n",
       "      <td>0.00237421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>115</td>\n",
       "      <td>s</td>\n",
       "      <td>111110101</td>\n",
       "      <td>0.00275694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   byte symbol       code   frequency\n",
       "0     0      \u0000      01110   0.0284127\n",
       "1     1      \u0001     110011   0.0197444\n",
       "2    10     \\n    0110101  0.00697332\n",
       "3   100      d   01000010  0.00314809\n",
       "4   101      e  110101111   0.0025088\n",
       "5   102      f   00101111  0.00298616\n",
       "6   103      g   00011000   0.0028726\n",
       "7   104      h   10000101  0.00378738\n",
       "8   105      i  110010111  0.00247305\n",
       "9   106      j  101101001  0.00226065\n",
       "10  107      k  111000010  0.00255716\n",
       "11  108      l   00110110  0.00307028\n",
       "12  109      m  111010011  0.00260974\n",
       "13   11      \n",
       "   11000010  0.00477786\n",
       "14  110      n   00101001  0.00295672\n",
       "15  111      o   00111110  0.00311865\n",
       "16  112      p    0110011  0.00692705\n",
       "17  113      q   00101010  0.00296303\n",
       "18  114      r  110000000  0.00237421\n",
       "19  115      s  111110101  0.00275694"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and showing data\n",
    "codes = create_huffman_df(hf_code, term_freq)\n",
    "codes.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save full huffman codes as CSV file\n",
    "codes.to_csv('../huffman_codes/sample1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate message average size\n",
    "msg_size_current = 8\n",
    "msg_size_weighted = 0\n",
    "\n",
    "for key, value in hf_code.items():\n",
    "    msg_size_weighted += len(value) * term_freq[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Current message average size (bits per symbol)\n",
    "msg_size_current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.783808280076634"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weighted message average size (bits per symbol)\n",
    "msg_size_weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real compression percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7 %\n"
     ]
    }
   ],
   "source": [
    "# Calculating compression ratio (%)\n",
    "compress_rate = (msg_size_current - msg_size_weighted) / msg_size_current\n",
    "print(round(compress_rate * 100, 2), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Main function:** compress a binary file using a huffman code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compress a binary file using a huffman code\n",
    "def compress_bin_file(byte_list, code_list):\n",
    "    bits_string = ''\n",
    "    compress_list = []\n",
    "    symbols_used = {}\n",
    "    \n",
    "    for symbol in byte_list:\n",
    "        key = str(symbol)\n",
    "        new_symbol = code_list[key]\n",
    "        compress_list.append(new_symbol)\n",
    "        \n",
    "        # Save frequency of length of used symbols\n",
    "        sym_len = len(new_symbol)\n",
    "        if sym_len in symbols_used:\n",
    "            symbols_used[sym_len] += 1\n",
    "        else:\n",
    "            symbols_used[sym_len] = 1\n",
    "    \n",
    "    # Create bits string\n",
    "    bits_string = \"\".join(compress_list)\n",
    "    \n",
    "    # Sort dict by key\n",
    "    symbols_used = sorted(symbols_used.items(), key=lambda x: x[0])\n",
    "    \n",
    "    # Return compressed file and used symbols\n",
    "    return bits_string, dict(symbols_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1110101111010001000110101000010111110010001101011000101001101010111001110011101110010000000100100111110111111111111101101110011100110101011100111001110101011100011111100010001000111001110011101111010011000000011010100111001000001110011100111000111000011000101111101111000011011111001110011101010011010100000011000010110110100101010010100100111001110011101100111111101011111110110000101110100000011101110100101111000001011010110110000001110011100001000111010100010011110101111100010010101111110011001100111010\n"
     ]
    }
   ],
   "source": [
    "# Compressing PNG image with Huffman code\n",
    "compress_file, symbols_used = compress_bin_file(image_byte_list, hf_code)\n",
    "print(compress_file[:508])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "451.83 KB\n"
     ]
    }
   ],
   "source": [
    "# Weight of the compressed PNG image (KB)\n",
    "print(round(len(compress_file) / 8 / 1024, 2), 'KB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464.38 KB\n"
     ]
    }
   ],
   "source": [
    "# Weight of the original PNG image (KB)\n",
    "print(round(len(image_byte_list) / 1024, 2), 'KB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5: 13511, 6: 50643, 7: 68876, 8: 234607, 9: 107890}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show frequency of length of used symbols\n",
    "symbols_used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compress Text file with Huffman Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example is with a textbook in English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading target image\n",
    "file_path = \"../data/text/book1-en.txt\"\n",
    "text_byte_list = get_file_bytes(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alphabet with 256 symbols\n",
    "term_freq = get_term_freq(text_byte_list)\n",
    "len(term_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999998"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize term frequency\n",
    "n = sum(term_freq.values())\n",
    "for term in term_freq:\n",
    "    term_freq[term] = term_freq[term] / n;\n",
    "sum(term_freq.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Huffman coding\n",
    "hf_code = hc.get_code(term_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>byte</th>\n",
       "      <th>symbol</th>\n",
       "      <th>code</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>\\n</td>\n",
       "      <td>101111</td>\n",
       "      <td>0.0174728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>d</td>\n",
       "      <td>01111</td>\n",
       "      <td>0.0300135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>e</td>\n",
       "      <td>1111</td>\n",
       "      <td>0.0929537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102</td>\n",
       "      <td>f</td>\n",
       "      <td>100100</td>\n",
       "      <td>0.0160457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103</td>\n",
       "      <td>g</td>\n",
       "      <td>100101</td>\n",
       "      <td>0.0162087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>104</td>\n",
       "      <td>h</td>\n",
       "      <td>0001</td>\n",
       "      <td>0.0493223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>105</td>\n",
       "      <td>i</td>\n",
       "      <td>0010</td>\n",
       "      <td>0.0496922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>106</td>\n",
       "      <td>j</td>\n",
       "      <td>0000100001</td>\n",
       "      <td>0.000665819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>107</td>\n",
       "      <td>k</td>\n",
       "      <td>0100001</td>\n",
       "      <td>0.00634397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>108</td>\n",
       "      <td>l</td>\n",
       "      <td>10011</td>\n",
       "      <td>0.0336131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>109</td>\n",
       "      <td>m</td>\n",
       "      <td>111001</td>\n",
       "      <td>0.0180574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>110</td>\n",
       "      <td>n</td>\n",
       "      <td>0101</td>\n",
       "      <td>0.0517024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>111</td>\n",
       "      <td>o</td>\n",
       "      <td>0110</td>\n",
       "      <td>0.0548374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>112</td>\n",
       "      <td>p</td>\n",
       "      <td>010010</td>\n",
       "      <td>0.0129926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>113</td>\n",
       "      <td>q</td>\n",
       "      <td>1110000001</td>\n",
       "      <td>0.000991966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>114</td>\n",
       "      <td>r</td>\n",
       "      <td>11101</td>\n",
       "      <td>0.0412147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>115</td>\n",
       "      <td>s</td>\n",
       "      <td>0011</td>\n",
       "      <td>0.0497518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>116</td>\n",
       "      <td>t</td>\n",
       "      <td>1010</td>\n",
       "      <td>0.0685228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>117</td>\n",
       "      <td>u</td>\n",
       "      <td>00000</td>\n",
       "      <td>0.0211582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>118</td>\n",
       "      <td>v</td>\n",
       "      <td>0111000</td>\n",
       "      <td>0.00675603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   byte symbol        code    frequency\n",
       "0    10     \\n      101111    0.0174728\n",
       "1   100      d       01111    0.0300135\n",
       "2   101      e        1111    0.0929537\n",
       "3   102      f      100100    0.0160457\n",
       "4   103      g      100101    0.0162087\n",
       "5   104      h        0001    0.0493223\n",
       "6   105      i        0010    0.0496922\n",
       "7   106      j  0000100001  0.000665819\n",
       "8   107      k     0100001   0.00634397\n",
       "9   108      l       10011    0.0336131\n",
       "10  109      m      111001    0.0180574\n",
       "11  110      n        0101    0.0517024\n",
       "12  111      o        0110    0.0548374\n",
       "13  112      p      010010    0.0129926\n",
       "14  113      q  1110000001  0.000991966\n",
       "15  114      r       11101    0.0412147\n",
       "16  115      s        0011    0.0497518\n",
       "17  116      t        1010    0.0685228\n",
       "18  117      u       00000    0.0211582\n",
       "19  118      v     0111000   0.00675603"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and showing data\n",
    "codes = create_huffman_df(hf_code, term_freq)\n",
    "codes.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save full huffman codes as CSV file\n",
    "codes.to_csv('../huffman_codes/sample2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate weighted message size average\n",
    "msg_size_current = 8\n",
    "msg_size_weighted = 0\n",
    "\n",
    "for key, value in hf_code.items():\n",
    "    msg_size_weighted += len(value) * term_freq[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Current message size average (bits per symbol)\n",
    "msg_size_current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.624532355844688"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weighted message size average (bits per symbol)\n",
    "msg_size_weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real compression percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.19 %\n"
     ]
    }
   ],
   "source": [
    "# Calculating compression ratio (%)\n",
    "compress_rate = (msg_size_current - msg_size_weighted) / msg_size_current\n",
    "print(round(compress_rate * 100, 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1110001010010000010011100010100100000101111000101001001011111011101011110111001010001111111001110010011110101100000100001111110110110101100111001000000000101011110101000011111111101100101110111000110001110000111011001100100001110011010010011011100001100011000001101001111001110011110001010110101000010100011111001101110111001110010100011111110111000000000011000100111111011101110000011010011110111000001111111110111100110000101101110101111111000011001111100110111000001010011100111111101110101111101110101111\n"
     ]
    }
   ],
   "source": [
    "# Compressing text file with Huffman code\n",
    "compress_file, symbols_used = compress_bin_file(text_byte_list, hf_code)\n",
    "print(compress_file[:508])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "709.66 KB\n"
     ]
    }
   ],
   "source": [
    "# Weight of the compressed text file (KB)\n",
    "print(round(len(compress_file) / 8 / 1024, 2), 'KB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1227.64 KB\n"
     ]
    }
   ],
   "source": [
    "# Weight of the original text file (KB)\n",
    "print(round(len(text_byte_list) / 1024, 2), 'KB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: 194944,\n",
       " 4: 599860,\n",
       " 5: 158394,\n",
       " 6: 217634,\n",
       " 7: 39957,\n",
       " 8: 4181,\n",
       " 9: 18481,\n",
       " 10: 14113,\n",
       " 11: 6396,\n",
       " 12: 1453,\n",
       " 13: 963,\n",
       " 14: 580,\n",
       " 15: 32,\n",
       " 16: 56,\n",
       " 18: 22,\n",
       " 19: 20,\n",
       " 20: 13}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show frequency of length of used symbols\n",
    "symbols_used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Decompress file with Huffman Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Simple approach\n",
    "Test with all huffman codes until the file is completely decompressed. The codes are sorted ascending by their length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompress a binary file using a huffman code\n",
    "def decompress_bin_file(byte_string, hf_code, forward=True):\n",
    "    start_time = timeit.default_timer()\n",
    "    byte_list = []\n",
    "    codes_size = []\n",
    "    inv_codes = {v: k for k, v in hf_code.items()}\n",
    "    \n",
    "    for code in inv_codes.keys():\n",
    "        n = len(code)\n",
    "        if not n in codes_size:\n",
    "            codes_size.append(n)\n",
    "    codes_size.sort(reverse = not forward)\n",
    "    \n",
    "    n_size = len(byte_string)\n",
    "    ix = 0\n",
    "    tries = 0\n",
    "    \n",
    "    while ix < n_size:\n",
    "        \n",
    "        for size in codes_size:\n",
    "            tries += 1\n",
    "            possible_code = byte_string[ix:ix + size]\n",
    "            \n",
    "            if possible_code in inv_codes.keys():\n",
    "                byte = int(inv_codes[possible_code])\n",
    "                byte_list.append(byte)\n",
    "                ix = ix + size\n",
    "                break\n",
    "    \n",
    "    # Elapsed time\n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    \n",
    "    # Algorithm accuracy\n",
    "    algo_accuracy = round(100 * len(byte_list) / tries / 8, 2)\n",
    "    \n",
    "    # Verbose\n",
    "    print(codes_size)\n",
    "    print('elapsed time', elapsed, 's')\n",
    "    print('tries:', tries, ', acurracy:', algo_accuracy, '%')\n",
    "    \n",
    "    return byte_list;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20]\n",
      "elapsed time 1.914795 s\n",
      "tries: 3299242 , acurracy: 4.76 %\n"
     ]
    }
   ],
   "source": [
    "# Decode/Decompress file using the Huffman code\n",
    "forward = True\n",
    "decompress_file = decompress_bin_file(compress_file, hf_code, forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1227.64 KB\n"
     ]
    }
   ],
   "source": [
    "# Weight of the original text file (KB)\n",
    "print(round(len(decompress_file) / 1024, 2), 'KB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing if the original file and the decompressed file are the same (equals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare if two files are equals for equality and element-wise\n",
    "def compare_files(file_a, file_b):\n",
    "    return np.array_equiv(file_a, file_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing files\n",
    "compare_files(text_byte_list, decompress_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Probabilistic approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with selected pseudo-random huffman codes, based on their probability of occurrence. <a href=\"#link_two\">[2]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Probabilistic Huffman Code from scratch\n",
    "class ProbHCodes:\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self):\n",
    "        self.prob_table = []\n",
    "        self.n_rows = 0\n",
    "        self.last_ix = -1\n",
    "    \n",
    "    # Returns the probabilistic codes table\n",
    "    def get_prob_table(self):\n",
    "        return self.prob_table\n",
    "    \n",
    "    # Function that creates the table with the the probability of use of codes in the decompression process\n",
    "    def create_prob_table(self, symbols):\n",
    "        self.total = sum(symbols.values())\n",
    "        cum = 0\n",
    "\n",
    "        for key, value in symbols.items():\n",
    "            curr = value / self.total\n",
    "            cum += curr\n",
    "            item = [key, value, curr, cum]\n",
    "            self.prob_table.append(item)\n",
    "        \n",
    "        self.n_rows = len(self.prob_table)\n",
    "        self.prob_table[self.n_rows - 1][3] = 1.0\n",
    "    \n",
    "    # Function that returns the size and index of the selected code\n",
    "    def get_prob_code(self):\n",
    "        prn = np.random.uniform(0, 1)\n",
    "        \n",
    "        while True:\n",
    "            for ix in range(self.n_rows):\n",
    "                item = self.prob_table[ix]\n",
    "                if prn <= item[3]:\n",
    "                    if ix == self.last_ix:\n",
    "                        break\n",
    "                    self.last_ix = ix\n",
    "                    return item[0], ix\n",
    "            prn = np.random.uniform(0, 1)\n",
    "    \n",
    "    # Function that updates the probability of use of codes\n",
    "    def update_prob_table(self, ix_code):\n",
    "        \n",
    "        if self.prob_table[ix_code][1] > 1:\n",
    "            self.prob_table[ix_code][1] -= 1\n",
    "        else:\n",
    "            self.prob_table.remove(self.prob_table[ix_code])\n",
    "            self.n_rows -= 1\n",
    "        self.total -= 1\n",
    "\n",
    "        cum = 0\n",
    "        for row in self.prob_table:\n",
    "            curr = row[1] / self.total\n",
    "            cum += curr\n",
    "            row[2] = curr\n",
    "            row[3] = cum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompress a binary file using a huffman code\n",
    "def decompress_bin_file_prob(byte_string, hf_code, symbols_used):\n",
    "    start_time = timeit.default_timer()\n",
    "    \n",
    "    byte_list = []\n",
    "    n_size = len(byte_string)\n",
    "    inv_codes = {v: k for k, v in hf_code.items()}\n",
    "    \n",
    "    # Create Probabilistic Huffman Codes table\n",
    "    phc = ProbHCodes()\n",
    "    phc.create_prob_table(symbols_used)\n",
    "    \n",
    "    # Get code based on probability\n",
    "    size, ix_code = phc.get_prob_code()\n",
    "    \n",
    "    ix = 0\n",
    "    tries = 0\n",
    "    while ix < n_size:\n",
    "        \n",
    "        while True:\n",
    "            tries += 1\n",
    "            possible_code = byte_string[ix:ix + size]\n",
    "            \n",
    "            if possible_code in inv_codes.keys():\n",
    "                byte = int(inv_codes[possible_code])\n",
    "                byte_list.append(byte)\n",
    "                ix = ix + size\n",
    "                break\n",
    "            \n",
    "            # Get code based on probability\n",
    "            size, ix_code = phc.get_prob_code()\n",
    "    \n",
    "    # Elapsed time\n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    \n",
    "    # Algorithm accuracy\n",
    "    algo_accuracy = round(100 * len(byte_list) / tries / 8, 2)\n",
    "    \n",
    "    # Verbose\n",
    "    print('elapsed time', elapsed, 's')\n",
    "    print('tries:', tries, ', acurracy:', algo_accuracy, '%')\n",
    "    \n",
    "    return byte_list;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hf_code len: 110 , symbols_used: 17\n"
     ]
    }
   ],
   "source": [
    "# Context\n",
    "print('hf_code len:', len(hf_code), ', symbols_used:', len(symbols_used))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time 56.3995674 s\n",
      "tries: 14382253 , acurracy: 1.09 %\n"
     ]
    }
   ],
   "source": [
    "# Decode/Decompress file using the Huffman code\n",
    "decompress_file2 = decompress_bin_file_prob(compress_file, hf_code, symbols_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1227.64 KB\n"
     ]
    }
   ],
   "source": [
    "# Weight of the original text file (KB)\n",
    "print(round(len(decompress_file2) / 1024, 2), 'KB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing if the original file and the decompressed file are the same (equals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing files\n",
    "compare_files(text_byte_list, decompress_file2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='link_one' href='https://en.wikipedia.org/wiki/Huffman_coding' target='_blank' >[1]</a> Wikipedia - Huffman coding.  \n",
    "<a name='link_two' href='https://en.wikipedia.org/wiki/Randomized_algorithm' target='_blank' >[2]</a> Wikipedia - Randomized algorithm.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p><a href=\"https://ansegura7.github.io/DataCompression/\">« Home</a></p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
